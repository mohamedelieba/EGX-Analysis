{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import to_date, regexp_replace, col, when\n",
    "from pyspark.sql.types import DoubleType\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_location = \"/home/elieba/.gc/alexy-de-bootcamp.json\"\n",
    "conf = SparkConf()\\\n",
    "    .setAppName(\"test\")\\\n",
    "    .setMaster(\"spark://de-bootcamp.us-central1-b.c.alexy-de-bootcamp.internal:7077\")\\\n",
    "    .set(\"spark.jars\", \"/home/elieba/spark/lib/spark-3.5-bigquery-0.42.0.jar,/home/elieba/spark/lib/gcs-connector-hadoop3-2.2.5.jar\")\\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\")\\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", credentials_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/16 12:28:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"google.cloud.auth.service.account.enable\", \"true\")\n",
    "hadoop_conf.set(\"google.cloud.auth.service.account.json.keyfile\", credentials_location)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .config(conf=sc.getConf())\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://de-bootcamp.us-central1-b.c.alexy-de-bootcamp.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://de-bootcamp.us-central1-b.c.alexy-de-bootcamp.internal:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb55b6719d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .csv(\"gs://project-egx-bucket/data/EGX-100_historical-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+---------+---------+-------+--------+\n",
      "|      Date|    Price|     Open|     High|      Low|   Vol.|Change %|\n",
      "+----------+---------+---------+---------+---------+-------+--------+\n",
      "|03/13/2025|12,209.73|12,115.24|12,231.83|12,115.24|  1.19B|   0.78%|\n",
      "|03/12/2025|12,115.24|12,006.13|12,129.40|12,006.13|  1.12B|   0.91%|\n",
      "|03/11/2025|12,006.13|11,968.97|12,006.13|11,909.95|748.99M|   0.31%|\n",
      "|03/10/2025|11,968.97|11,983.17|12,067.38|11,958.60|680.35M|  -0.12%|\n",
      "|03/09/2025|11,983.17|11,867.56|12,016.53|11,867.56|881.74M|   0.97%|\n",
      "|03/06/2025|11,867.56|11,840.45|11,872.73|11,840.45|698.42M|   0.23%|\n",
      "|03/05/2025|11,840.45|11,934.24|11,944.43|11,817.58|774.32M|  -0.79%|\n",
      "|03/04/2025|11,934.24|11,967.75|11,986.40|11,922.81|756.93M|  -0.28%|\n",
      "|03/03/2025|11,967.75|11,935.95|11,994.63|11,935.95|798.81M|   0.27%|\n",
      "|03/02/2025|11,935.95|11,910.97|11,970.31|11,910.97|592.19M|   0.21%|\n",
      "|02/27/2025|11,910.97|11,905.04|11,970.62|11,901.84|  1.18B|   0.05%|\n",
      "|02/26/2025|11,905.04|11,904.20|11,981.92|11,892.87|771.66M|   0.01%|\n",
      "|02/25/2025|11,904.20|11,975.33|12,028.94|11,896.44|843.20M|  -0.59%|\n",
      "|02/24/2025|11,975.33|11,977.66|12,041.99|11,973.15|  1.06B|  -0.02%|\n",
      "|02/23/2025|11,977.66|11,875.52|11,996.66|11,862.26|868.82M|   0.86%|\n",
      "|02/20/2025|11,875.52|11,824.94|11,891.05|11,824.94|852.24M|   0.43%|\n",
      "|02/19/2025|11,824.94|11,803.00|11,873.16|11,803.00|  1.13B|   0.19%|\n",
      "|02/18/2025|11,803.00|11,731.71|11,803.00|11,731.71|  1.07B|   0.61%|\n",
      "|02/17/2025|11,731.71|11,735.55|11,810.88|11,719.03|  1.05B|  -0.03%|\n",
      "|02/16/2025|11,735.55|11,504.52|11,735.55|11,504.52|  1.11B|   2.01%|\n",
      "+----------+---------+---------+---------+---------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[Date: string, Price: string, Open: string, High: string, Low: string, Vol.: string, Change %: string]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.withColumn(\"Date\", to_date(col(\"Date\"), \"MM/dd/yyyy\"))  # Convert Date\n",
    "df = df.withColumn(\"Close\", regexp_replace(col(\"Price\"), \",\", \"\").cast(DoubleType()))\n",
    "df = df.withColumn(\"Open\", regexp_replace(col(\"Open\"), \",\", \"\").cast(DoubleType()))\n",
    "df = df.withColumn(\"High\", regexp_replace(col(\"High\"), \",\", \"\").cast(DoubleType()))\n",
    "df = df.withColumn(\"Low\", regexp_replace(col(\"Low\"), \",\", \"\").cast(DoubleType()))\n",
    "df = df.drop(\"Price\")\n",
    "df = df.withColumn(\"Points_diff\", df.Close - df.Open)\n",
    "\n",
    "\n",
    "df = df.withColumn(\"Volume\", \n",
    "    when(col(\"`Vol.`\").endswith(\"B\"), \n",
    "         regexp_replace(col(\"`Vol.`\"), \"B\", \"\").cast(DoubleType()) * 1e9)\n",
    "    .when(col(\"`Vol.`\").endswith(\"M\"), \n",
    "          regexp_replace(col(\"`Vol.`\"), \"M\", \"\").cast(DoubleType()) * 1e6)\n",
    "    .otherwise(col(\"`Vol.`\").cast(DoubleType()))\n",
    ")\n",
    "df = df.drop(\"Vol.\")\n",
    "\n",
    "df = df.withColumn(\"Change %\", \n",
    "    regexp_replace(col(\"`Change %`\"), \"%\", \"\").cast(DoubleType())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+--------+--------+--------+-------------------+--------------------+\n",
      "|      Date|    Open|    High|     Low|Change %|   Close|        Points_diff|              Volume|\n",
      "+----------+--------+--------+--------+--------+--------+-------------------+--------------------+\n",
      "|2025-03-13|12115.24|12231.83|12115.24|    0.78|12209.73|  94.48999999999978|              1.19E9|\n",
      "|2025-03-12|12006.13| 12129.4|12006.13|    0.91|12115.24| 109.11000000000058|              1.12E9|\n",
      "|2025-03-11|11968.97|12006.13|11909.95|    0.31|12006.13| 37.159999999999854|            7.4899E8|\n",
      "|2025-03-10|11983.17|12067.38| 11958.6|   -0.12|11968.97|-14.200000000000728|            6.8035E8|\n",
      "|2025-03-09|11867.56|12016.53|11867.56|    0.97|11983.17| 115.61000000000058|            8.8174E8|\n",
      "|2025-03-06|11840.45|11872.73|11840.45|    0.23|11867.56| 27.109999999998763|            6.9842E8|\n",
      "|2025-03-05|11934.24|11944.43|11817.58|   -0.79|11840.45| -93.78999999999905|            7.7432E8|\n",
      "|2025-03-04|11967.75| 11986.4|11922.81|   -0.28|11934.24| -33.51000000000022|            7.5693E8|\n",
      "|2025-03-03|11935.95|11994.63|11935.95|    0.27|11967.75| 31.799999999999272|            7.9881E8|\n",
      "|2025-03-02|11910.97|11970.31|11910.97|    0.21|11935.95| 24.980000000001382|            5.9219E8|\n",
      "|2025-02-27|11905.04|11970.62|11901.84|    0.05|11910.97|  5.929999999998472|              1.18E9|\n",
      "|2025-02-26| 11904.2|11981.92|11892.87|    0.01|11905.04| 0.8400000000001455|            7.7166E8|\n",
      "|2025-02-25|11975.33|12028.94|11896.44|   -0.59| 11904.2|  -71.1299999999992|             8.432E8|\n",
      "|2025-02-24|11977.66|12041.99|11973.15|   -0.02|11975.33|-2.3299999999999272|              1.06E9|\n",
      "|2025-02-23|11875.52|11996.66|11862.26|    0.86|11977.66| 102.13999999999942|            8.6882E8|\n",
      "|2025-02-20|11824.94|11891.05|11824.94|    0.43|11875.52|  50.57999999999993|            8.5224E8|\n",
      "|2025-02-19| 11803.0|11873.16| 11803.0|    0.19|11824.94|  21.94000000000051|              1.13E9|\n",
      "|2025-02-18|11731.71| 11803.0|11731.71|    0.61| 11803.0|  71.29000000000087|1.0700000000000001E9|\n",
      "|2025-02-17|11735.55|11810.88|11719.03|   -0.03|11731.71|-3.8400000000001455|              1.05E9|\n",
      "|2025-02-16|11504.52|11735.55|11504.52|    2.01|11735.55| 231.02999999999884|              1.11E9|\n",
      "+----------+--------+--------+--------+--------+--------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load To BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('gs://project-egx-bucket/data/egx_history', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4651 rows to alexy-de-bootcamp.EGX_dataset.egx_history\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "client = bigquery.Client()\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    source_format=bigquery.SourceFormat.PARQUET,\n",
    "    write_disposition=\"WRITE_TRUNCATE\",  \n",
    ")\n",
    "\n",
    "uri = \"gs://project-egx-bucket/data/egx_history/*.parquet\"\n",
    "table_id = \"alexy-de-bootcamp.EGX_dataset.egx_history\"\n",
    "\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri, table_id, job_config=job_config\n",
    ")\n",
    "load_job.result() \n",
    "\n",
    "print(f\"Loaded {load_job.output_rows} rows to {table_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
